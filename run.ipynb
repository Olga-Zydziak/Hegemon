{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "79c03994-1129-4123-84fc-528f93f57f4c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/envs/hegemon_env/lib/python3.11/site-packages/pydantic/_internal/_model_construction.py:63: UserWarning: `validate_explainability_config` overrides an existing Pydantic `@model_validator` decorator\n",
      "  warnings.warn(f'`{k}` overrides an existing Pydantic `{existing.decorator_info.decorator_repr}` decorator')\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import os\n",
    "import json\n",
    "import logging\n",
    "from google.cloud import secretmanager\n",
    "\n",
    "#hegemon dependencis\n",
    "from hegemon.explainability.visualizer import HeatmapGenerator\n",
    "from hegemon.config.settings import get_settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "30e9cc50-90ae-45d3-a075-20cf7b631a6c",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "üìç GCP Project: dark-data-discovery\n",
      "üìç Location: us-central1\n"
     ]
    }
   ],
   "source": [
    "PROJECT_ID = \"dark-data-discovery\"\n",
    "LOCATION = \"us-central1\"\n",
    "\n",
    "print(f\"üìç GCP Project: {PROJECT_ID}\")\n",
    "print(f\"üìç Location: {LOCATION}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "145efff6-e199-47c6-a6e9-7a3abd60b915",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ ANTHROPIC_API_KEY: **********uwAA\n"
     ]
    }
   ],
   "source": [
    "def get_secret(project_id, secret_id, version_id=\"latest\"):\n",
    "    client = secretmanager.SecretManagerServiceClient()\n",
    "    name = f\"projects/{project_id}/secrets/{secret_id}/versions/{version_id}\"\n",
    "    response = client.access_secret_version(request={\"name\": name})\n",
    "    return response.payload.data.decode(\"UTF-8\")\n",
    "\n",
    "try:\n",
    "    key = get_secret(PROJECT_ID, \"ANTHROPIC_API_KEY\")\n",
    "    print(f\"‚úÖ ANTHROPIC_API_KEY: {'*' * 10}{key[-4:]}\")\n",
    "except Exception as e:\n",
    "    print(f\"‚ùå Failed to get ANTHROPIC_API_KEY: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "793044ce-63c8-492a-8605-b14460f89684",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Environment configured for Vertex AI\n",
      "   Explainability enabled: true\n",
      "   Classifier model: gemini-2.5-flash\n"
     ]
    }
   ],
   "source": [
    "# Kom√≥rka 1: Setup\n",
    "# ENABLE EXPLAINABILITY (przez os.environ)\n",
    "os.environ[\"HEGEMON_EXPLAINABILITY_ENABLED\"] = \"true\"\n",
    "os.environ[\"HEGEMON_EXPLAINABILITY_SEMANTIC_FINGERPRINT\"] = \"true\"\n",
    "os.environ[\"HEGEMON_EXPLAINABILITY_CLASSIFIER_MODEL\"] = \"gemini-2.5-flash\"  # Vertex AI model\n",
    "\n",
    "# Setup logging dla Jupyter\n",
    "logging.basicConfig(\n",
    "    level=logging.INFO,\n",
    "    format=\"%(asctime)s - %(name)s - %(levelname)s - %(message)s\",\n",
    "    force=True\n",
    ")\n",
    "logger = logging.getLogger(__name__)\n",
    "\n",
    "print(\"‚úÖ Environment configured for Vertex AI\")\n",
    "print(f\"   Explainability enabled: {os.environ.get('HEGEMON_EXPLAINABILITY_ENABLED')}\")\n",
    "print(f\"   Classifier model: {os.environ.get('HEGEMON_EXPLAINABILITY_CLASSIFIER_MODEL')}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4c9247d3-9fa2-4bbc-b956-60bd87240383",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-12 23:47:49,318 - hegemon.config.settings - WARNING - Explainability enabled but no Google API key found. Classifier will fail.\n",
      "2025-10-12 23:47:49,319 - hegemon.config.settings - INFO - ‚úÖ Sceptyk will use Vertex AI (Application Default Credentials)\n",
      "2025-10-12 23:47:49,321 - hegemon.config.settings - INFO - ‚úÖ All required authentication validated\n",
      "2025-10-12 23:47:49,321 - hegemon.config.settings - INFO - ‚úÖ HEGEMON Settings initialized (GCP Project: dark-data-discovery)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explainability Layers:\n",
      "  Layer 6 (Semantic): True\n",
      "  Layer 2 (Epistemic): True\n",
      "================================================================================\n",
      "‚úÖ STEP 2: Settings loaded and verified\n",
      "================================================================================\n",
      "GCP Project ID: dark-data-discovery\n",
      "GCP Location: us-central1\n",
      "\n",
      "üîç EXPLAINABILITY SETTINGS:\n",
      "   enabled: True\n",
      "   semantic_fingerprint: True\n",
      "   classifier_model: gemini-2.0-flash\n",
      "   cache_size: 1000\n",
      "================================================================================\n",
      "\n",
      "‚úÖ SUCCESS: Explainability is ENABLED!\n",
      "   Proceed to next cells.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Kom√≥rka 2: Import Hegemon modules\n",
    "from hegemon.explainability.visualizer import HeatmapGenerator\n",
    "\n",
    "\n",
    "# Verify settings\n",
    "settings = get_settings()\n",
    "print(\"Explainability Layers:\")\n",
    "print(f\"  Layer 6 (Semantic): {settings.explainability_semantic_fingerprint}\")\n",
    "print(f\"  Layer 2 (Epistemic): {settings.explainability_epistemic_uncertainty}\")\n",
    "\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"‚úÖ STEP 2: Settings loaded and verified\")\n",
    "print(\"=\" * 80)\n",
    "print(f\"GCP Project ID: {settings.gcp_project_id}\")\n",
    "print(f\"GCP Location: {settings.gcp_location}\")\n",
    "print()\n",
    "print(\"üîç EXPLAINABILITY SETTINGS:\")\n",
    "print(f\"   enabled: {settings.explainability_enabled}\")\n",
    "print(f\"   semantic_fingerprint: {settings.explainability_semantic_fingerprint}\")\n",
    "print(f\"   classifier_model: {settings.explainability_classifier_model}\")\n",
    "print(f\"   cache_size: {settings.explainability_cache_size}\")\n",
    "print(\"=\" * 80)\n",
    "\n",
    "# CRITICAL CHECK\n",
    "if not settings.explainability_enabled:\n",
    "    print(\"\\n‚ùå ERROR: Explainability is DISABLED!\")\n",
    "    print(\"   This means environment variable was set AFTER settings were cached.\")\n",
    "    print(\"   SOLUTION: Restart kernel and run cells in correct order.\")\n",
    "else:\n",
    "    print(\"\\n‚úÖ SUCCESS: Explainability is ENABLED!\")\n",
    "    print(\"   Proceed to next cells.\")\n",
    "\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c96cac9-2b91-422c-bf31-0f53daeb2889",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-12 23:47:49,350 - hegemon.graph_hitl_v2 - INFO - üèóÔ∏è Building HEGEMON graph with Phase 2.2 feedback-aware agents...\n",
      "2025-10-12 23:47:49,378 - hegemon.graph_hitl_v2 - INFO - ‚úÖ HEGEMON graph Phase 2.2 compiled successfully!\n",
      "2025-10-12 23:47:49,379 - hegemon.graph_hitl_v2 - INFO -    Enhanced: Feedback-aware agents with effectiveness tracking\n",
      "2025-10-12 23:47:49,379 - hegemon.graph_hitl_v2 - INFO -    Checkpoints: post_thesis, post_evaluation, pre_synthesis\n",
      "2025-10-12 23:47:49,383 - hegemon.agents_hitl - INFO - üî• KATALIZATOR (anthropic/claude-sonnet-4-5-20250929): Generating Thesis (Cycle 1) [NO FEEDBACK]\n",
      "2025-10-12 23:47:49,391 - hegemon.agents_hitl - INFO - ‚úÖ KATALIZATOR: Thesis generated (2278 chars)\n",
      "2025-10-12 23:47:49,392 - hegemon.explainability.collector - WARNING - Failed to get explainability collector: 'HegemonSettings' object has no attribute 'explainability'\n",
      "2025-10-12 23:47:49,394 - hegemon.hitl.checkpoints - INFO - üî≠ Observer mode active - skipping post_thesis checkpoint\n",
      "2025-10-12 23:47:49,395 - hegemon.agents_hitl - INFO - ‚öîÔ∏è SCEPTYK (google/gemini-2.5-pro via Vertex AI): Generating Antithesis (Cycle 1) [NO FEEDBACK]\n",
      "2025-10-12 23:47:49,396 - langchain_google_vertexai.chat_models - WARNING - Unexpected argument 'timeout' provided to ChatVertexAI.\n",
      "/home/jupyter/olga_zydziak/version_beta/Folder/hegemon_mvp/hegemon/agents_hitl.py:385: UserWarning: WARNING! timeout is not default parameter.\n",
      "                timeout was transferred to model_kwargs.\n",
      "                Please confirm that timeout is what you intended.\n",
      "  llm = get_llm_for_agent(\"Sceptyk\")\n",
      "2025-10-12 23:47:49,413 - hegemon.agents_hitl - INFO - ‚úÖ SCEPTYK: Antithesis generated (2036 chars)\n",
      "2025-10-12 23:47:49,414 - hegemon.explainability.collector - WARNING - Failed to get explainability collector: 'HegemonSettings' object has no attribute 'explainability'\n",
      "2025-10-12 23:47:49,415 - hegemon.agents_hitl - INFO - ‚öñÔ∏è GUBERNATOR (anthropic/claude-sonnet-4-5-20250929): Evaluating Consensus (Cycle 1) [NO FEEDBACK]\n",
      "2025-10-12 23:48:01,189 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-10-12 23:48:01,220 - hegemon.agents_hitl - INFO - ‚úÖ GUBERNATOR: Consensus Score = 0.52\n",
      "2025-10-12 23:48:01,220 - hegemon.explainability.collector - WARNING - Failed to get explainability collector: 'HegemonSettings' object has no attribute 'explainability'\n",
      "2025-10-12 23:48:01,223 - hegemon.hitl.checkpoints - INFO - üî≠ Observer mode active - skipping post_evaluation checkpoint\n",
      "2025-10-12 23:48:01,224 - hegemon.graph_hitl_v2 - INFO - üîÑ Consensus too low (0.52 < 0.7). Continuing debate (cycle 2).\n",
      "2025-10-12 23:48:01,225 - hegemon.graph_hitl_v2 - INFO - üìà Starting debate cycle 2\n",
      "2025-10-12 23:48:01,227 - hegemon.agents_hitl - INFO - üî• KATALIZATOR (anthropic/claude-sonnet-4-5-20250929): Generating Thesis (Cycle 2) [NO FEEDBACK]\n",
      "2025-10-12 23:48:15,115 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-10-12 23:48:15,149 - hegemon.agents_hitl - INFO - ‚úÖ KATALIZATOR: Thesis generated (2224 chars)\n",
      "2025-10-12 23:48:15,149 - hegemon.explainability.collector - WARNING - Failed to get explainability collector: 'HegemonSettings' object has no attribute 'explainability'\n",
      "2025-10-12 23:48:15,151 - hegemon.hitl.checkpoints - INFO - üî≠ Observer mode active - skipping post_thesis checkpoint\n",
      "2025-10-12 23:48:15,152 - hegemon.agents_hitl - INFO - ‚öîÔ∏è SCEPTYK (google/gemini-2.5-pro via Vertex AI): Generating Antithesis (Cycle 2) [NO FEEDBACK]\n",
      "2025-10-12 23:48:15,153 - langchain_google_vertexai.chat_models - WARNING - Unexpected argument 'timeout' provided to ChatVertexAI.\n",
      "/home/jupyter/olga_zydziak/version_beta/Folder/hegemon_mvp/hegemon/agents_hitl.py:385: UserWarning: WARNING! timeout is not default parameter.\n",
      "                timeout was transferred to model_kwargs.\n",
      "                Please confirm that timeout is what you intended.\n",
      "  llm = get_llm_for_agent(\"Sceptyk\")\n",
      "2025-10-12 23:48:35,187 - hegemon.agents_hitl - INFO - ‚úÖ SCEPTYK: Antithesis generated (2154 chars)\n",
      "2025-10-12 23:48:35,188 - hegemon.explainability.collector - WARNING - Failed to get explainability collector: 'HegemonSettings' object has no attribute 'explainability'\n",
      "2025-10-12 23:48:35,189 - hegemon.agents_hitl - INFO - ‚öñÔ∏è GUBERNATOR (anthropic/claude-sonnet-4-5-20250929): Evaluating Consensus (Cycle 2) [NO FEEDBACK]\n",
      "2025-10-12 23:48:48,224 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-10-12 23:48:48,236 - hegemon.agents_hitl - INFO - ‚úÖ GUBERNATOR: Consensus Score = 0.64\n",
      "2025-10-12 23:48:48,236 - hegemon.explainability.collector - WARNING - Failed to get explainability collector: 'HegemonSettings' object has no attribute 'explainability'\n",
      "2025-10-12 23:48:48,238 - hegemon.hitl.checkpoints - INFO - üî≠ Observer mode active - skipping post_evaluation checkpoint\n",
      "2025-10-12 23:48:48,239 - hegemon.graph_hitl_v2 - INFO - üîÑ Consensus too low (0.64 < 0.7). Continuing debate (cycle 3).\n",
      "2025-10-12 23:48:48,240 - hegemon.graph_hitl_v2 - INFO - üìà Starting debate cycle 3\n",
      "2025-10-12 23:48:48,241 - hegemon.agents_hitl - INFO - üî• KATALIZATOR (anthropic/claude-sonnet-4-5-20250929): Generating Thesis (Cycle 3) [NO FEEDBACK]\n",
      "2025-10-12 23:49:04,580 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-10-12 23:49:04,593 - hegemon.agents_hitl - INFO - ‚úÖ KATALIZATOR: Thesis generated (2292 chars)\n",
      "2025-10-12 23:49:04,593 - hegemon.explainability.collector - WARNING - Failed to get explainability collector: 'HegemonSettings' object has no attribute 'explainability'\n",
      "2025-10-12 23:49:04,595 - hegemon.hitl.checkpoints - INFO - üî≠ Observer mode active - skipping post_thesis checkpoint\n",
      "2025-10-12 23:49:04,596 - hegemon.agents_hitl - INFO - ‚öîÔ∏è SCEPTYK (google/gemini-2.5-pro via Vertex AI): Generating Antithesis (Cycle 3) [NO FEEDBACK]\n",
      "2025-10-12 23:49:04,597 - langchain_google_vertexai.chat_models - WARNING - Unexpected argument 'timeout' provided to ChatVertexAI.\n",
      "/home/jupyter/olga_zydziak/version_beta/Folder/hegemon_mvp/hegemon/agents_hitl.py:385: UserWarning: WARNING! timeout is not default parameter.\n",
      "                timeout was transferred to model_kwargs.\n",
      "                Please confirm that timeout is what you intended.\n",
      "  llm = get_llm_for_agent(\"Sceptyk\")\n",
      "2025-10-12 23:49:26,434 - hegemon.agents_hitl - INFO - ‚úÖ SCEPTYK: Antithesis generated (480 chars)\n",
      "2025-10-12 23:49:26,435 - hegemon.explainability.collector - WARNING - Failed to get explainability collector: 'HegemonSettings' object has no attribute 'explainability'\n",
      "2025-10-12 23:49:26,436 - hegemon.agents_hitl - INFO - ‚öñÔ∏è GUBERNATOR (anthropic/claude-sonnet-4-5-20250929): Evaluating Consensus (Cycle 3) [NO FEEDBACK]\n",
      "2025-10-12 23:49:37,988 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-10-12 23:49:37,999 - hegemon.agents_hitl - INFO - ‚úÖ GUBERNATOR: Consensus Score = 0.73\n",
      "2025-10-12 23:49:38,000 - hegemon.explainability.collector - WARNING - Failed to get explainability collector: 'HegemonSettings' object has no attribute 'explainability'\n",
      "2025-10-12 23:49:38,002 - hegemon.hitl.checkpoints - INFO - üî≠ Observer mode active - skipping post_evaluation checkpoint\n",
      "2025-10-12 23:49:38,003 - hegemon.graph_hitl_v2 - INFO - ‚úÖ Consensus threshold met (0.73 >= 0.7) after 3 cycles. Moving to pre-synthesis checkpoint.\n",
      "2025-10-12 23:49:38,004 - hegemon.hitl.checkpoints - INFO - üî≠ Observer mode active - skipping pre_synthesis checkpoint\n",
      "2025-10-12 23:49:38,005 - hegemon.agents_hitl - INFO - üîÆ SYNTEZATOR (anthropic/claude-opus-4-1-20250805): Generating Final Plan (Cycle 3) [NO FEEDBACK]\n",
      "2025-10-12 23:50:21,442 - httpx - INFO - HTTP Request: POST https://api.anthropic.com/v1/messages \"HTTP/1.1 200 OK\"\n",
      "2025-10-12 23:50:21,457 - hegemon.agents_hitl - INFO - ‚úÖ SYNTEZATOR: Plan generated (4 agents, 12 steps)\n",
      "2025-10-12 23:50:21,458 - hegemon.explainability.collector - WARNING - Failed to get explainability collector: 'HegemonSettings' object has no attribute 'explainability'\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚úÖ Completed in 3 cycles\n",
      "   Consensus: 0.73\n"
     ]
    }
   ],
   "source": [
    "from hegemon.graph_hitl_v2 import create_hegemon_graph_hitl_v2\n",
    "from hegemon.hitl import HumanFeedback\n",
    "\n",
    "# Create graph\n",
    "graph = create_hegemon_graph_hitl_v2()\n",
    "\n",
    "# Test with observer mode (no feedback)\n",
    "initial_state = {\n",
    "    \"mission\": \"Design a simple web API\",\n",
    "    \"intervention_mode\": \"observer\",\n",
    "    \"contributions\": [],\n",
    "    \"cycle_count\": 1,\n",
    "    \"current_consensus_score\": 0.0,\n",
    "    \"final_plan\": None,\n",
    "    \"current_checkpoint\": None,\n",
    "    \"human_feedback_history\": [],\n",
    "    \"paused_at\": None,\n",
    "    \"revision_count_per_checkpoint\": {},\n",
    "    \"checkpoint_snapshots\": {},\n",
    "}\n",
    "\n",
    "result = graph.invoke(initial_state, config={\"recursion_limit\": 100})\n",
    "\n",
    "print(f\"‚úÖ Completed in {result['cycle_count']} cycles\")\n",
    "print(f\"   Consensus: {result['current_consensus_score']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "a64487af-b040-4e8e-912e-5d728e72d39b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-10-12 23:50:32,514 - hegemon.hitl.effectiveness - INFO - Effectiveness score: 0.45 (Fair) - Structural: 0.61, Keywords: 0.33\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Overall: 0.45 (Fair)\n",
      "Structural: 0.61\n",
      "Keyword Match: 0.33\n"
     ]
    }
   ],
   "source": [
    "from hegemon.hitl import compute_feedback_effectiveness, HumanFeedback\n",
    "\n",
    "feedback = HumanFeedback(\n",
    "    checkpoint=\"post_thesis_cycle_1\",\n",
    "    decision=\"revise\",\n",
    "    guidance=\"Add cost estimates and timeline\",\n",
    ")\n",
    "\n",
    "original_output = \"We should use microservices.\"\n",
    "revised_output = \"We should use microservices with estimated cost of $50K over 6 months.\"\n",
    "\n",
    "# Compute effectiveness\n",
    "result = compute_feedback_effectiveness(original_output, revised_output, feedback)\n",
    "\n",
    "print(f\"Overall: {result['overall']:.2f} ({result['interpretation']})\")\n",
    "print(f\"Structural: {result['structural']:.2f}\")\n",
    "print(f\"Keyword Match: {result['keyword_match']:.2f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e98734bc-dffe-47fd-ba5c-ae98f5dcf6f5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "‚ÑπÔ∏è No feedback history (observer mode or no interventions)\n"
     ]
    }
   ],
   "source": [
    "from hegemon.hitl import detect_feedback_contradictions, generate_contradiction_report\n",
    "\n",
    "# Analyze feedback history - BEZPIECZNY spos√≥b\n",
    "feedback_history = result.get(\"human_feedback_history\", [])\n",
    "\n",
    "if not feedback_history:\n",
    "    print(\"‚ÑπÔ∏è No feedback history (observer mode or no interventions)\")\n",
    "else:\n",
    "    contradictions = detect_feedback_contradictions(feedback_history)\n",
    "    \n",
    "    if contradictions:\n",
    "        report = generate_contradiction_report(contradictions)\n",
    "        print(report)\n",
    "        \n",
    "        # Save report\n",
    "        with open(\"contradiction_report.md\", \"w\") as f:\n",
    "            f.write(report)\n",
    "        \n",
    "        print(f\"\\nüíæ Report saved to: contradiction_report.md\")\n",
    "    else:\n",
    "        print(\"‚úÖ No contradictions detected\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "0090a3ff-bcf3-4f4f-9167-5ed49057ec14",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "'mission'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[16]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mhegemon\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mhitl\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m build_agent_prompt_with_feedback\n\u001b[32m      3\u001b[39m \u001b[38;5;66;03m# U≈ºyj RESULT z debaty (nie 'state')\u001b[39;00m\n\u001b[32m      4\u001b[39m enhanced_system, enhanced_user = build_agent_prompt_with_feedback(\n\u001b[32m      5\u001b[39m     state=result,  \u001b[38;5;66;03m# ‚Üê U≈ºyj wyniku debaty\u001b[39;00m\n\u001b[32m      6\u001b[39m     agent_id=\u001b[33m\"\u001b[39m\u001b[33mKatalizator\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m      7\u001b[39m     base_system_prompt=\u001b[33m\"\u001b[39m\u001b[33mYou are Katalizator agent.\u001b[39m\u001b[33m\"\u001b[39m,\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m     base_user_prompt=\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMission: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mresult\u001b[49m\u001b[43m[\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mmission\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m,  \u001b[38;5;66;03m# ‚Üê Dynamicznie pobierz mission\u001b[39;00m\n\u001b[32m      9\u001b[39m     include_debate_context=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m     10\u001b[39m )\n\u001b[32m     12\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mEnhanced System Prompt:\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     13\u001b[39m \u001b[38;5;28mprint\u001b[39m(enhanced_system)\n",
      "\u001b[31mKeyError\u001b[39m: 'mission'"
     ]
    }
   ],
   "source": [
    "from hegemon.hitl import build_agent_prompt_with_feedback\n",
    "\n",
    "# U≈ºyj RESULT z debaty (nie 'state')\n",
    "enhanced_system, enhanced_user = build_agent_prompt_with_feedback(\n",
    "    state=result,  # ‚Üê U≈ºyj wyniku debaty\n",
    "    agent_id=\"Katalizator\",\n",
    "    base_system_prompt=\"You are Katalizator agent.\",\n",
    "    base_user_prompt=f\"Mission: {result['mission']}\",  # ‚Üê Dynamicznie pobierz mission\n",
    "    include_debate_context=True,\n",
    ")\n",
    "\n",
    "print(\"Enhanced System Prompt:\")\n",
    "print(enhanced_system)\n",
    "print(\"\\n\" + \"=\"*80 + \"\\n\")\n",
    "print(\"Enhanced User Prompt:\")\n",
    "print(enhanced_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e055148b-0462-45fa-84f1-1610e1b9b98e",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "ENHANCED SYSTEM PROMPT (with feedback):\n",
      "================================================================================\n",
      "You are Katalizator agent.\n",
      "\n",
      "‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó\n",
      "‚ïë HUMAN FEEDBACK (1 revision requested)                              ‚ïë\n",
      "‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù\n",
      "\n",
      "The human reviewed your previous output and requested changes:\n",
      "\n",
      "üîÑ **Decision: REVISE**\n",
      "\n",
      "üìù **Guidance:**\n",
      "\"Add detailed cost breakdown and ROI analysis\"\n",
      "\n",
      "üéØ **Priority Items to Emphasize:**\n",
      "‚Ä¢ Cost estimation\n",
      "‚Ä¢ ROI timeline\n",
      "\n",
      "‚ö†Ô∏è **Concerns to Address:**\n",
      "‚Ä¢ Hidden operational costs\n",
      "‚Ä¢ Scalability costs\n",
      "\n",
      "**ACTION REQUIRED:** Please incorporate this feedback in your revised output.\n",
      "\n",
      "\n",
      "================================================================================\n",
      "ENHANCED USER PROMPT:\n",
      "================================================================================\n",
      "Mission: Design microservices platform\n"
     ]
    }
   ],
   "source": [
    "from hegemon.hitl import build_agent_prompt_with_feedback, HumanFeedback\n",
    "\n",
    "# Stw√≥rz testowy state Z feedbackiem\n",
    "test_state = {\n",
    "    \"mission\": \"Design microservices platform\",\n",
    "    \"contributions\": [],\n",
    "    \"cycle_count\": 1,\n",
    "    \"current_consensus_score\": 0.0,\n",
    "    \"final_plan\": None,\n",
    "    \"intervention_mode\": \"reviewer\",\n",
    "    \"current_checkpoint\": None,\n",
    "    \"human_feedback_history\": [\n",
    "        HumanFeedback(\n",
    "            checkpoint=\"post_thesis_cycle_1\",\n",
    "            decision=\"revise\",\n",
    "            guidance=\"Add detailed cost breakdown and ROI analysis\",\n",
    "            priority_claims=[\"Cost estimation\", \"ROI timeline\"],\n",
    "            flagged_concerns=[\"Hidden operational costs\", \"Scalability costs\"],\n",
    "        ).model_dump()\n",
    "    ],\n",
    "    \"paused_at\": None,\n",
    "    \"revision_count_per_checkpoint\": {},\n",
    "    \"checkpoint_snapshots\": {},\n",
    "}\n",
    "\n",
    "# Teraz u≈ºyj tego state\n",
    "enhanced_system, enhanced_user = build_agent_prompt_with_feedback(\n",
    "    state=test_state,\n",
    "    agent_id=\"Katalizator\",\n",
    "    base_system_prompt=\"You are Katalizator agent.\",\n",
    "    base_user_prompt=f\"Mission: {test_state['mission']}\",\n",
    "    include_debate_context=False,\n",
    ")\n",
    "\n",
    "print(\"=\" * 80)\n",
    "print(\"ENHANCED SYSTEM PROMPT (with feedback):\")\n",
    "print(\"=\" * 80)\n",
    "print(enhanced_system)\n",
    "\n",
    "print(\"\\n\" + \"=\" * 80)\n",
    "print(\"ENHANCED USER PROMPT:\")\n",
    "print(\"=\" * 80)\n",
    "print(enhanced_user)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "500019b7-1851-4f26-9d6c-9550c74e5c98",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "kernel": "hegemon_env",
   "name": "workbench-notebooks.m129",
   "type": "gcloud",
   "uri": "us-docker.pkg.dev/deeplearning-platform-release/gcr.io/workbench-notebooks:m129"
  },
  "kernelspec": {
   "display_name": "Python 3.11 (hegemon_dev)",
   "language": "python",
   "name": "hegemon_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
